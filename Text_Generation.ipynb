{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhotNoorin/Algorithm-practice/blob/main/Text_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN code for Text Generation"
      ],
      "metadata": {
        "id": "EKra-u1aXMCP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name: Noorin Nasir Khot\n",
        "\n",
        "ID:2024KPAD1007"
      ],
      "metadata": {
        "id": "ixTZyUdoes5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "Ri7h7OakXDrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Dataset\n",
        "dataset = [\n",
        "    \"I love machine learning.\",\n",
        "    \"Text generation is fascinating.\",\n",
        "    \"Artificial intelligence is evolving.\",\n",
        "    \"I am learning deep learning.\",\n",
        "    \"Recurrent neural networks are great for sequential data.\",\n",
        "    \"Natural language processing is a subfield of AI.\",\n",
        "    \"Data science involves many techniques.\",\n",
        "    \"The weather today is sunny and warm.\",\n",
        "    \"Python is a great programming language.\",\n",
        "    \"I am studying for my exams.\",\n",
        "    \"The dog chased the ball.\",\n",
        "    \"He ran fast down the street.\",\n",
        "    \"I enjoy coding in Python.\",\n",
        "    \"The city is very crowded in the morning.\",\n",
        "    \"I prefer coffee over tea.\",\n",
        "    \"She loves reading books about history.\",\n",
        "    \"My favorite color is blue.\",\n",
        "    \"They played basketball in the park.\",\n",
        "    \"I want to visit Paris someday.\",\n",
        "    \"The sunset was beautiful last evening.\",\n",
        "    \"We are learning about convolutional neural networks.\",\n",
        "    \"This tutorial is very helpful for beginners.\",\n",
        "    \"The movie was an incredible experience.\",\n",
        "    \"She studied hard for her final project.\",\n",
        "    \"I am going to the gym this evening.\"\n",
        "]"
      ],
      "metadata": {
        "id": "vBvoVvKQXIhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Preprocessing the text\n",
        "words = ' '.join(dataset).lower().split()  # Convert to lowercase and split into words"
      ],
      "metadata": {
        "id": "FE3IIcRKXgFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a vocabulary\n",
        "vocab = sorted(set(words))\n",
        "vocab_size = len(vocab)"
      ],
      "metadata": {
        "id": "GWfXhiohXj7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create word-to-index and index-to-word mappings\n",
        "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "idx_to_word = {idx: word for idx, word in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "3ctgmzrLXnKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert dataset sentences to sequences of integers\n",
        "sequences = [np.array([word_to_idx[word] for word in sentence.lower().split()]) for sentence in dataset]"
      ],
      "metadata": {
        "id": "Mkervp7SXqsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare X (input sequences) and y (next word predictions)\n",
        "X_data = []\n",
        "y_data = []"
      ],
      "metadata": {
        "id": "pMw9Jh0nXurH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sequence in sequences:\n",
        "    for i in range(1, len(sequence)):\n",
        "        X_data.append(sequence[:i])  # Input is the first i words\n",
        "        y_data.append(sequence[i])   # Output is the next word"
      ],
      "metadata": {
        "id": "PtX1UUOoXy73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding sequences to make them the same length\n",
        "max_seq_len = max(len(seq) for seq in X_data)\n",
        "X_data = [np.pad(seq, (max_seq_len - len(seq), 0), mode='constant') for seq in X_data]\n",
        "X_data = np.array(X_data)\n",
        "y_data = np.array(y_data)"
      ],
      "metadata": {
        "id": "cbZCq6LaX3HX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Define a simple RNN model\n",
        "hidden_size = 10\n",
        "learning_rate = 0.01\n",
        "epochs = 1000"
      ],
      "metadata": {
        "id": "Yxe3MfqNX7Dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize weights and biases\n",
        "Wxh = np.random.randn(hidden_size, vocab_size) * 0.01  # Input to hidden weights\n",
        "Whh = np.random.randn(hidden_size, hidden_size) * 0.01  # Hidden to hidden weights\n",
        "Why = np.random.randn(vocab_size, hidden_size) * 0.01  # Hidden to output weights\n",
        "bh = np.zeros((hidden_size, 1))  # Hidden bias\n",
        "by = np.zeros((vocab_size, 1))  # Output bias"
      ],
      "metadata": {
        "id": "BNbL8XI_YALH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function for forward pass\n",
        "def forward_pass(X, h_prev):\n",
        "    # Compute hidden state\n",
        "    h = np.tanh(np.dot(Wxh, X) + np.dot(Whh, h_prev) + bh)\n",
        "    # Compute output\n",
        "    y = np.dot(Why, h) + by\n",
        "    return y, h"
      ],
      "metadata": {
        "id": "cIKtTf-0YDdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function (softmax cross-entropy)\n",
        "def loss(y_pred, y_true):\n",
        "    return -np.log(np.exp(y_pred[y_true]) / np.sum(np.exp(y_pred)))"
      ],
      "metadata": {
        "id": "mk3HkA4HYFyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Train the RNN using gradient descent\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    h_prev = np.zeros((hidden_size, 1))  # Initial hidden state\n",
        "\n",
        "    for i in range(len(X_data)):\n",
        "        X = np.zeros((vocab_size, 1))  # One-hot encoded input\n",
        "        X[X_data[i][0]] = 1\n",
        "\n",
        "        target = y_data[i]\n",
        "\n",
        "        # Forward pass\n",
        "        y_pred, h = forward_pass(X, h_prev)\n",
        "\n",
        "        # Calculate loss (cross-entropy)\n",
        "        total_loss += loss(y_pred, target)\n",
        "\n",
        "        # Backpropagation (Gradient descent)\n",
        "        dL_dy = np.exp(y_pred) / np.sum(np.exp(y_pred))  # Softmax derivative\n",
        "        dL_dy[target] -= 1\n",
        "\n",
        "        # Gradients for Why, by\n",
        "        dL_dWhy = np.dot(dL_dy, h.T)\n",
        "        dL_dby = dL_dy\n",
        "\n",
        "        # Gradients for hidden layer (h)\n",
        "        dL_dh = np.dot(Why.T, dL_dy)\n",
        "        dL_dhraw = (1 - h * h) * dL_dh  # Derivative of tanh\n",
        "\n",
        "        # Gradients for Wxh, Whh, bh\n",
        "        dL_dWxh = np.dot(dL_dhraw, X.T)\n",
        "        dL_dWhh = np.dot(dL_dhraw, h_prev.T)\n",
        "        dL_dbh = dL_dhraw\n",
        "\n",
        "        # Update weights and biases using gradient descent\n",
        "        Wxh -= learning_rate * dL_dWxh\n",
        "        Whh -= learning_rate * dL_dWhh\n",
        "        Why -= learning_rate * dL_dWhy\n",
        "        bh -= learning_rate * dL_dbh\n",
        "        by -= learning_rate * dL_dby\n",
        "\n",
        "        # Set h_prev for the next iteration\n",
        "        h_prev = h\n",
        "\n",
        "    # Print loss every 100 epochs\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {total_loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWmR4CplYFvg",
        "outputId": "27c8769e-c5f5-4427-dea7-5f2af90c548c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: [584.2232238]\n",
            "Epoch 100, Loss: [555.83788938]\n",
            "Epoch 200, Loss: [546.28716184]\n",
            "Epoch 300, Loss: [492.60866035]\n",
            "Epoch 400, Loss: [374.4695367]\n",
            "Epoch 500, Loss: [325.35538455]\n",
            "Epoch 600, Loss: [297.55315642]\n",
            "Epoch 700, Loss: [334.88081792]\n",
            "Epoch 800, Loss: [337.53965615]\n",
            "Epoch 900, Loss: [300.99287194]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Generate text using the trained RNN model\n",
        "def generate_text(seed_word, length=20):\n",
        "    # Convert seed_word to lowercase to match the preprocessed data\n",
        "    seed_word = seed_word.lower()\n",
        "\n",
        "    # Check if seed_word is in the vocabulary\n",
        "    if seed_word not in word_to_idx:\n",
        "        raise ValueError(f\"Seed word '{seed_word}' not found in the vocabulary.\")\n",
        "\n",
        "    word_idx = word_to_idx[seed_word]\n",
        "    h_prev = np.zeros((hidden_size, 1))\n",
        "    generated_text = [seed_word]\n",
        "\n",
        "    for _ in range(length):\n",
        "        X = np.zeros((vocab_size, 1))\n",
        "        X[word_idx] = 1\n",
        "        y_pred, h = forward_pass(X, h_prev)\n",
        "\n",
        "        # Sample the next word\n",
        "        prob = np.exp(y_pred) / np.sum(np.exp(y_pred))  # Softmax\n",
        "        word_idx = np.random.choice(range(vocab_size), p=prob.ravel())\n",
        "\n",
        "        generated_text.append(idx_to_word[word_idx])\n",
        "        h_prev = h\n",
        "\n",
        "    return ' '.join(generated_text)"
      ],
      "metadata": {
        "id": "u9ZJ0x6JYLOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGaHkDkxTNE8",
        "outputId": "5dab4f4a-3e4f-4dc0-cc4d-d72adba85ec6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text:  natural morning. language processing many techniques. prefer language science involves techniques. morning. weather language processing tea. data. warm. language science involves\n"
          ]
        }
      ],
      "source": [
        "# Test text generation\n",
        "seed_word = \"Natural\"  # works with the lowercase \"i\"\n",
        "generated_sentence = generate_text(seed_word, length=20)\n",
        "print(\"Generated Text: \", generated_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_word = \"I\"\n",
        "generated_sentence = generate_text(seed_word, length=20)\n",
        "print(\"Generated Text: \", generated_sentence)"
      ],
      "metadata": {
        "id": "vJj-rUnUUwY7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "540e33ce-0933-41e0-e2c2-5dcc778ef231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text:  i morning. language coffee ai. techniques. exams. language science processing techniques. language. weather processing involves many data. prefer prefer science involves\n"
          ]
        }
      ]
    }
  ]
}